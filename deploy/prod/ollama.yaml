apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama
  namespace: argocd
spec:
  project: application
  source:
    repoURL: https://otwld.github.io/ollama-helm
    chart: ollama
    targetRevision: 1.13.0
    helm:
      releaseName: ollama
      valuesObject:
        persistentVolume:
          enabled: true
          accessModes: [ "ReadWriteMany" ]
          storageClass: ai-efs
        ollama:
          models:
            pull:
              - gemma3:27b-it-qat # 20Gb # vision # 128k
            run:
              - gemma3:27b-it-qat
          gpu:
            enabled: true
  
  destination:
    server: https://kubernetes.default.svc
    namespace: kivoyo
  
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
  
  revisionHistoryLimit: 10
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: codelama
  namespace: argocd
spec:
  project: application
  source:
    repoURL: https://otwld.github.io/ollama-helm
    chart: ollama
    targetRevision: 1.13.0
    helm:
      releaseName: codelama
      valuesObject:
        persistentVolume:
          enabled: true
          accessModes: [ "ReadWriteMany" ]
          storageClass: ai-efs
        ollama:
          models:
            pull:
              - deepseek-coder-v2:16b-lite-base-q8_0 #17GB
              - llama3.1:8b # 4.9GB # tools
              - nomic-embed-text # 274 # embed #
            run:
              - deepseek-coder-v2:16b-lite-base-q8_0
              - llama3.1:8b
              - nomic-embed-text
          gpu:
            enabled: true
  
  destination:
    server: https://kubernetes.default.svc
    namespace: kivoyo
  
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
  
  revisionHistoryLimit: 10