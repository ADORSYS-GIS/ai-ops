db:
  enabled: true
  instances: 2
  storage:
    size: 10Gi
    storageClass: ai-ebs
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"


litellm:
  fullnameOverride: litellm
  replicaCount: 1
  
  db:
    useExisting: true
    deployStandalone: false
    endpoint: "litellm-pg-rw"
    database: app
    secret:
      name: litellm-pg-app
      usernameKey: username
      passwordKey: password
      
  envVars:
    {
      USE_DDTRACE: "false",
      LITELLM_MODE: "production",
    }
  
  # if set, use this secret for the master key; otherwise, autogenerate a new one
  masterkeySecretName: "litellm-master-key"
  
  # if set, use this secret key for the master key; otherwise, use the default key
  masterkeySecretKey: "master_key"
  
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: "app.kubernetes.io/name"
                operator: In
                values:
                  - litellm
          topologyKey: "kubernetes.io/hostname"
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 3
  
  environmentSecrets:
    - litellm-openai-api-key
    - litellm-gemini-api-key
    - litellm-fireworks-key
    - litellm-anthropic-api-key
    - litellm-redis-secret
  
  ingress:
    enabled: true
    hosts:
      - host: api.ai.kivoyo.com
        paths:
          - path: /
            pathType: Prefix
    className: alb
    annotations:
      alb.ingress.kubernetes.io/tags: Environment=dev,Owner=adorsys-gis
      alb.ingress.kubernetes.io/load-balancer-name: ai-adorsys-gis
      alb.ingress.kubernetes.io/listen-ports: |
        [
          {
            "HTTP":80
          },
          {
            "HTTPS": 443
          }
        ]
      alb.ingress.kubernetes.io/ssl-redirect: "443"
      alb.ingress.kubernetes.io/scheme: "internet-facing"
      alb.ingress.kubernetes.io/target-type: "ip"
      alb.ingress.kubernetes.io/certificate-arn: "arn:aws:acm:eu-central-1:571075516563:certificate/980a6ebb-a87e-4cfb-b8bf-3d0e5da5acf5"
      external-dns.alpha.kubernetes.io/hostname: "api.ai.kivoyo.com"
      alb.ingress.kubernetes.io/healthcheck-interval-seconds: "15"
      alb.ingress.kubernetes.io/healthcheck-timeout-seconds: "5"
      alb.ingress.kubernetes.io/healthy-threshold-count: "2"
      alb.ingress.kubernetes.io/unhealthy-threshold-count: "2"
  
  proxy_config:
    general_settings:
      user_header_name: X-OpenWebUI-User-Email
    litellm_settings:
      cache: True
      cache_params: # set cache params for redis
        type: redis
        namespace: "litellm.caching.caching"
    model_list:
      # At least one model must exist for the proxy to start.
      - model_name: qwen3-coder-480b-a35b-instruct
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct
          drop_params: true
        model_info:
          supports_function_calling: true
          supports_computer_use: true
          input_cost_per_token: 0.45e-6
          output_cost_per_token: 1.8e-6
      - model_name: kimi-k2-instruct-0905
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905
          drop_params: true
        model_info:
          supports_function_calling: true
          supports_computer_use: true
          input_cost_per_token: 0.6e-6
          output_cost_per_token: 2.5e-6
      - model_name: deepseek-v3p1
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/deepseek-v3p1
          drop_params: true
        model_info:
          supports_function_calling: true
          supports_computer_use: true
          input_cost_per_token: 0.56e-6
          output_cost_per_token: 1.68e-6
      - model_name: qwen3-235b-a22b-instruct-2507
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507
          drop_params: true
        model_info:
          supports_function_calling: true
          input_cost_per_token: 0.22e-6
          output_cost_per_token: 0.88e-6
      - model_name: llama4-maverick-instruct-basic
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic
          drop_params: true
        model_info:
          supports_function_calling: true
          input_cost_per_token: 0.22e-6
          output_cost_per_token: 0.88e-6
      - model_name: llama-v3p1-8b-instruct
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct
          drop_params: true
        model_info:
          supports_function_calling: true
          input_cost_per_token: 0.20e-6
          output_cost_per_token: 0.20e-6
      - model_name: gpt-oss-120b
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/gpt-oss-120b
          drop_params: true
        model_info:
          input_cost_per_token: 0.15e-6
          output_cost_per_token: 0.6e-6
      - model_name: gpt-oss-20b #128k context window
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/gpt-oss-20b
          drop_params: true
        model_info:
          input_cost_per_token: 0.07e-6
          output_cost_per_token: 0.3e-6
      - model_name: qwen3-235b-a22b-thinking-2507 #256k context window
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507
          drop_params: true
          thinking: {"type": "enabled", "budget_tokens": 1024}
          merge_reasoning_content_in_choices: true
        model_info:
          input_cost_per_token: 0.22e-6
          output_cost_per_token: 0.88e-6
          supports_reasoning: true
      - model_name: qwen3-coder-30b-a3b-instruct #256k context window
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct
          drop_params: true
        model_info:
          input_cost_per_token: 0.15e-6
          output_cost_per_token: 0.6e-6
      - model_name: qwen3-30b-a3b #128k context window
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b
          drop_params: true
          thinking: {"type": "enabled", "budget_tokens": 1024}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_reasoning: true
          input_cost_per_token: 0.15e-6
          output_cost_per_token: 0.6e-6
      - model_name: qwen3-235b-a22b #128k context window
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b
          drop_params: true
        model_info:
          supports_reasoning: true
          input_cost_per_token: 0.22e-6
          output_cost_per_token: 0.88e-6
      - model_name: glm-4p5
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/glm-4p5
          drop_params: true
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
          input_cost_per_token: 0.55e-6
          output_cost_per_token: 2.19e-6
      - model_name: deepseek-v3p1-terminus
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus
          drop_params: true
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
          input_cost_per_token: 0.56e-6
          output_cost_per_token: 1.68e-6
            
      - model_name: claude-sonnet-4
        litellm_params:
          model: anthropic/claude-sonnet-4-20250514
          thinking: {"type": "enabled", "budget_tokens": 1024}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
          
      - model_name: o4-mini
        litellm_params:
          model: openai/o4-mini
          drop_params: true
        model_info:
          supports_function_calling: true
          supports_vision: true
      - model_name: o4-mini-deep-research
        litellm_params:
          model: openai/o4-mini-deep-research
      - model_name: gpt-4.1
        litellm_params:
          model: openai/gpt-4.1
          drop_params: true
        model_info:
          supports_function_calling: true
      - model_name: gpt-4.1-mini
        litellm_params:
          model: openai/gpt-4.1-mini
          drop_params: true
        model_info:
          supports_function_calling: true
      - model_name: gpt-5
        litellm_params:
          model: openai/gpt-5
          drop_params: true
          thinking: {"type": "enabled", "budget_tokens": 1024}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
          supports_vision: true
      - model_name: gpt-5-mini
        litellm_params:
          model: openai/gpt-5-mini
          drop_params: true
          thinking: {"type": "enabled", "budget_tokens": 1024}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
          supports_vision: true
      - model_name: gpt-5-nano
        litellm_params:
          model: openai/gpt-5-nano
          drop_params: true
        model_info:
          supports_function_calling: true
          supports_vision: true
      - model_name: codex-mini-latest
        litellm_params:
          model: openai/codex-mini-latest
          drop_params: true
        model_info:
          supports_function_calling: true
          supports_vision: true
      - model_name: text-embedding-3-large
        litellm_params:
          model: openai/text-embedding-3-large
        model_info:
          mode: embedding

      - model_name: dall-e-3
        litellm_params:
          model: openai/dall-e-3
        model_info:
          mode: image_generation
      - model_name: gpt-image-1
        litellm_params:
          model: openai/gpt-image-1
        model_info:
          mode: image_generation
      - model_name: whisper-1
        litellm_params:
          model: openai/whisper-1
        model_info:
          mode: audio_transcription
      - model_name: gpt-4o-mini-audio
        litellm_params:
          model: openai/gpt-4o-mini-audio-preview-2024-12-17
        model_info:
          mode: audio_transcription
      - model_name: gpt-4o-transcribe
        litellm_params:
          model: openai/gpt-4o-transcribe
        model_info:
          mode: audio_transcription
      - model_name: gpt-4o-mini-tts
        litellm_params:
          model: openai/gpt-4o-mini-tts
        model_info:
          mode: audio_speech

      - model_name: gemini-2.5-flash
        litellm_params:
          model: gemini/gemini-2.5-flash
          drop_params: true
        model_info:
          supports_function_calling: true
      - model_name: gemini-2.5-pro-reasoning
        litellm_params:
          model: gemini/gemini-2.5-pro
          drop_params: true
          thinking: {"type": "enabled"}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
      - model_name: gemini-2.5-pro-reasoning-1024
        litellm_params:
          model: gemini/gemini-2.5-pro
          drop_params: true
          thinking: {"type": "enabled", "budget_tokens": 1024}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
      - model_name: gemini-2.5-pro-reasoning-4096
        litellm_params:
          model: gemini/gemini-2.5-pro
          drop_params: true
          thinking: {"type": "enabled", "budget_tokens": 4096}
          merge_reasoning_content_in_choices: true
        model_info:
          supports_function_calling: true
      - model_name: gemini-2.5-flash-lite
        litellm_params:
          model: gemini/gemini-2.5-flash-lite
          drop_params: true
        model_info:
          supports_function_calling: true